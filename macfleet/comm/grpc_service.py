"""gRPC control plane for MacFleet cluster coordination.

Provides server and client implementations for cluster control messages
including registration, heartbeats, synchronization barriers, and training commands.
"""

import asyncio
import time
from concurrent import futures
from typing import Callable, Optional

import grpc

from macfleet.comm.proto import control_pb2, control_pb2_grpc
from macfleet.core.config import (
    ClusterState,
    NodeConfig,
    ThermalState,
    TrainingConfig,
)


class ClusterControlServicer(control_pb2_grpc.ClusterControlServicer):
    """gRPC service implementation for cluster coordination.

    Runs on the master node and handles:
    - Node registration
    - Heartbeats
    - Synchronization barriers
    - Training control
    """

    def __init__(
        self,
        cluster_state: ClusterState,
        tensor_addr: str,
        tensor_port: int,
        on_register: Optional[Callable[[NodeConfig], None]] = None,
        on_heartbeat: Optional[Callable[[int, float, str], None]] = None,
    ):
        """Initialize the servicer.

        Args:
            cluster_state: Shared cluster state object.
            tensor_addr: Address for tensor transfers.
            tensor_port: Port for tensor transfers.
            on_register: Callback when a node registers.
            on_heartbeat: Callback on heartbeat (rank, throughput, thermal).
        """
        self._state = cluster_state
        self._tensor_addr = tensor_addr
        self._tensor_port = tensor_port
        self._on_register = on_register
        self._on_heartbeat = on_heartbeat
        self._next_rank = 1  # Rank 0 is reserved for master
        self._barriers: dict[str, set[int]] = {}
        self._barrier_events: dict[str, asyncio.Event] = {}
        self._lock = asyncio.Lock()

    def Register(
        self,
        request: control_pb2.RegisterRequest,
        context: grpc.ServicerContext,
    ) -> control_pb2.RegisterResponse:
        """Handle node registration."""
        # Assign rank
        rank = self._next_rank
        self._next_rank += 1

        # Calculate workload weight based on GPU cores
        # Simple heuristic: weight proportional to GPU cores
        total_cores = sum(n.gpu_cores for n in self._state.nodes.values())
        total_cores += request.gpu_cores

        # Create node config
        node = NodeConfig(
            hostname=request.hostname,
            ip_address=request.ip_address,
            gpu_cores=request.gpu_cores,
            ram_gb=request.ram_gb,
            memory_bandwidth_gbps=request.memory_bandwidth_gbps,
            tensor_port=request.tensor_port,
            rank=rank,
            workload_weight=request.gpu_cores / total_cores if total_cores > 0 else 0.5,
        )

        # Add to cluster state
        self._state.add_node(node)

        # Recalculate all weights
        self._recalculate_weights()

        # Callback
        if self._on_register:
            self._on_register(node)

        return control_pb2.RegisterResponse(
            assigned_rank=rank,
            workload_weight=node.workload_weight,
            world_size=self._state.world_size,
            master_tensor_addr=self._tensor_addr,
            master_tensor_port=self._tensor_port,
        )

    def _recalculate_weights(self) -> None:
        """Recalculate workload weights for all nodes."""
        total_cores = sum(n.gpu_cores for n in self._state.nodes.values())
        if total_cores == 0:
            return

        for node in self._state.nodes.values():
            node.workload_weight = node.gpu_cores / total_cores

    def Heartbeat(
        self,
        request: control_pb2.HeartbeatRequest,
        context: grpc.ServicerContext,
    ) -> control_pb2.HeartbeatResponse:
        """Handle heartbeat from a worker."""
        node = self._state.get_node(request.rank)
        current_weight = node.workload_weight if node else 0.0

        # Callback
        if self._on_heartbeat:
            self._on_heartbeat(
                request.rank,
                request.throughput_samples_per_sec,
                request.thermal_state,
            )

        # Check if we need to rebalance due to thermal throttling
        new_weight = current_weight
        if request.thermal_state in ("serious", "critical"):
            # Reduce workload for throttled nodes
            new_weight = current_weight * 0.7

        return control_pb2.HeartbeatResponse(
            acknowledged=True,
            new_workload_weight=new_weight,
            should_stop=False,
        )

    def SyncBarrier(
        self,
        request: control_pb2.BarrierRequest,
        context: grpc.ServicerContext,
    ) -> control_pb2.BarrierResponse:
        """Handle synchronization barrier."""
        barrier_id = request.barrier_id
        rank = request.rank

        # Initialize barrier tracking
        if barrier_id not in self._barriers:
            self._barriers[barrier_id] = set()

        self._barriers[barrier_id].add(rank)
        nodes_at_barrier = len(self._barriers[barrier_id])

        # Check if all nodes have reached the barrier
        proceed = nodes_at_barrier >= self._state.world_size

        if proceed:
            # Clean up barrier state
            del self._barriers[barrier_id]

        return control_pb2.BarrierResponse(
            proceed=proceed,
            nodes_at_barrier=nodes_at_barrier,
        )

    def StartTraining(
        self,
        request: control_pb2.TrainingConfigProto,
        context: grpc.ServicerContext,
    ) -> control_pb2.Ack:
        """Handle start training command."""
        self._state.training_active = True
        self._state.current_epoch = 0
        self._state.current_step = 0

        return control_pb2.Ack(
            success=True,
            message="Training started",
        )

    def StopTraining(
        self,
        request: control_pb2.StopRequest,
        context: grpc.ServicerContext,
    ) -> control_pb2.Ack:
        """Handle stop training command."""
        self._state.training_active = False

        return control_pb2.Ack(
            success=True,
            message=f"Training stopped: {request.reason}",
        )

    def GetClusterState(
        self,
        request: control_pb2.Empty,
        context: grpc.ServicerContext,
    ) -> control_pb2.ClusterStateProto:
        """Return current cluster state."""
        nodes = []
        for node in self._state.nodes.values():
            nodes.append(control_pb2.NodeInfoProto(
                rank=node.rank,
                hostname=node.hostname,
                ip_address=node.ip_address,
                gpu_cores=node.gpu_cores,
                ram_gb=node.ram_gb,
                memory_bandwidth_gbps=node.memory_bandwidth_gbps,
                tensor_port=node.tensor_port,
                workload_weight=node.workload_weight,
                status="connected",
            ))

        status = "training" if self._state.training_active else "idle"

        return control_pb2.ClusterStateProto(
            world_size=self._state.world_size,
            nodes=nodes,
            training_active=self._state.training_active,
            current_epoch=self._state.current_epoch,
            current_step=self._state.current_step,
            training_status=status,
        )

    def Broadcast(
        self,
        request: control_pb2.BroadcastRequest,
        context: grpc.ServicerContext,
    ) -> control_pb2.Ack:
        """Handle broadcast request."""
        # For now, just acknowledge - actual broadcast logic in coordinator
        return control_pb2.Ack(
            success=True,
            message=f"Broadcast {request.message_type} received",
        )


class GRPCServer:
    """gRPC server wrapper for the cluster control service."""

    def __init__(
        self,
        servicer: ClusterControlServicer,
        host: str = "0.0.0.0",
        port: int = 50051,
        max_workers: int = 10,
    ):
        """Initialize the server.

        Args:
            servicer: The service implementation.
            host: Host to bind to.
            port: Port to bind to.
            max_workers: Max thread pool workers.
        """
        self._servicer = servicer
        self._host = host
        self._port = port
        self._max_workers = max_workers
        self._server: Optional[grpc.Server] = None

    def start(self) -> None:
        """Start the gRPC server."""
        self._server = grpc.server(
            futures.ThreadPoolExecutor(max_workers=self._max_workers)
        )
        control_pb2_grpc.add_ClusterControlServicer_to_server(
            self._servicer, self._server
        )
        self._server.add_insecure_port(f"{self._host}:{self._port}")
        self._server.start()

    def stop(self, grace: float = 5.0) -> None:
        """Stop the gRPC server."""
        if self._server:
            self._server.stop(grace)
            self._server = None

    def wait_for_termination(self, timeout: Optional[float] = None) -> bool:
        """Wait for the server to terminate."""
        if self._server:
            return self._server.wait_for_termination(timeout)
        return True

    @property
    def is_running(self) -> bool:
        """Check if server is running."""
        return self._server is not None


class ClusterControlClient:
    """gRPC client for connecting to the cluster coordinator."""

    def __init__(
        self,
        master_addr: str,
        master_port: int = 50051,
    ):
        """Initialize the client.

        Args:
            master_addr: Address of the master node.
            master_port: gRPC port of the master.
        """
        self._addr = f"{master_addr}:{master_port}"
        self._channel: Optional[grpc.Channel] = None
        self._stub: Optional[control_pb2_grpc.ClusterControlStub] = None

    def connect(self) -> None:
        """Connect to the master."""
        self._channel = grpc.insecure_channel(self._addr)
        self._stub = control_pb2_grpc.ClusterControlStub(self._channel)

    def disconnect(self) -> None:
        """Disconnect from the master."""
        if self._channel:
            self._channel.close()
            self._channel = None
            self._stub = None

    def register(
        self,
        hostname: str,
        ip_address: str,
        gpu_cores: int,
        ram_gb: int,
        memory_bandwidth_gbps: float,
        tensor_port: int,
    ) -> tuple[int, float, int, str, int]:
        """Register this node with the cluster.

        Returns:
            Tuple of (rank, workload_weight, world_size, master_tensor_addr, master_tensor_port).
        """
        if not self._stub:
            raise RuntimeError("Not connected to master")

        request = control_pb2.RegisterRequest(
            hostname=hostname,
            ip_address=ip_address,
            gpu_cores=gpu_cores,
            ram_gb=ram_gb,
            memory_bandwidth_gbps=memory_bandwidth_gbps,
            tensor_port=tensor_port,
        )

        response = self._stub.Register(request)

        return (
            response.assigned_rank,
            response.workload_weight,
            response.world_size,
            response.master_tensor_addr,
            response.master_tensor_port,
        )

    def heartbeat(
        self,
        rank: int,
        throughput: float = 0.0,
        thermal_state: str = "nominal",
        current_step: int = 0,
    ) -> tuple[bool, float, bool]:
        """Send a heartbeat to the master.

        Returns:
            Tuple of (acknowledged, new_workload_weight, should_stop).
        """
        if not self._stub:
            raise RuntimeError("Not connected to master")

        request = control_pb2.HeartbeatRequest(
            rank=rank,
            throughput_samples_per_sec=throughput,
            thermal_state=thermal_state,
            timestamp_ms=int(time.time() * 1000),
            current_step=current_step,
        )

        response = self._stub.Heartbeat(request)

        return (
            response.acknowledged,
            response.new_workload_weight,
            response.should_stop,
        )

    def sync_barrier(
        self,
        rank: int,
        step: int,
        barrier_id: str,
    ) -> tuple[bool, int]:
        """Wait at a synchronization barrier.

        Returns:
            Tuple of (proceed, nodes_at_barrier).
        """
        if not self._stub:
            raise RuntimeError("Not connected to master")

        request = control_pb2.BarrierRequest(
            rank=rank,
            step=step,
            barrier_id=barrier_id,
        )

        response = self._stub.SyncBarrier(request)

        return (response.proceed, response.nodes_at_barrier)

    def get_cluster_state(self) -> dict:
        """Get the current cluster state.

        Returns:
            Dictionary with cluster state information.
        """
        if not self._stub:
            raise RuntimeError("Not connected to master")

        response = self._stub.GetClusterState(control_pb2.Empty())

        nodes = []
        for node in response.nodes:
            nodes.append({
                "rank": node.rank,
                "hostname": node.hostname,
                "ip_address": node.ip_address,
                "gpu_cores": node.gpu_cores,
                "ram_gb": node.ram_gb,
                "workload_weight": node.workload_weight,
                "status": node.status,
            })

        return {
            "world_size": response.world_size,
            "nodes": nodes,
            "training_active": response.training_active,
            "current_epoch": response.current_epoch,
            "current_step": response.current_step,
            "training_status": response.training_status,
        }

    def start_training(self, config: TrainingConfig) -> bool:
        """Signal the cluster to start training.

        Returns:
            True if successful.
        """
        if not self._stub:
            raise RuntimeError("Not connected to master")

        request = control_pb2.TrainingConfigProto(
            epochs=config.epochs,
            batch_size=config.batch_size,
            learning_rate=config.learning_rate,
            compression=config.compression.value,
            topk_ratio=config.topk_ratio,
            checkpoint_every=config.checkpoint_every,
            checkpoint_dir=config.checkpoint_dir,
            device=config.device,
        )

        response = self._stub.StartTraining(request)
        return response.success

    def stop_training(self, reason: str = "User request") -> bool:
        """Signal the cluster to stop training.

        Returns:
            True if successful.
        """
        if not self._stub:
            raise RuntimeError("Not connected to master")

        request = control_pb2.StopRequest(
            reason=reason,
            save_checkpoint=True,
        )

        response = self._stub.StopTraining(request)
        return response.success

    @property
    def is_connected(self) -> bool:
        """Check if connected to master."""
        return self._stub is not None
